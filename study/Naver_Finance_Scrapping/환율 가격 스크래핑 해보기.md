

# 환율 스크래핑 해보기

> 저번에는 NaverFinance 에서 주식가격을 스크래핑 해보았습니다. 이번에는 환율들을 스크래핑 해보겠습니다





## 1. url 분석

우선 스크래핑할 url 부터 확인해보자.

NaverFinance 의 메인 페이지 url	-	https://finance.naver.com/

환율 관련 url	-	https://finance.naver.com/marketindex/?tabSel=exchange#tab_section

​	: 	NaverFiance 의 환율 url 에서 내리면 다음과 같은 환율 정보가 있다

![Screenshot_15](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_15.png)

​	각 환율의 세부 정보를 보고 싶으면 원하는 통화의 링크를 눌러주면 된다



​	미국 USD를 눌러보았다 밑의 그림과 같이 USD에 대한 통화 정보가 나온다. URL 에 `marketindexCd=FX_USDKRW` 가 추가된 것을 보고 다른 통화도 비슷한 형식인걸 유추할 수 있다.

![Screenshot_18](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_18.png)

주식정보와 똑같이 밑에 일별시세가 있고 일별시세에 정보가 다른 링크에 들어가 있다.



![Screenshot_21](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_21.png)



NaveFinance 에서 환율에 대한 url 을 정리해보면 다음과 같다

- NaverFinance 의 메인 페이지 url - `https://finance.naver.com/`
- 각 통화별 환율 정보 url - `https://finance.naver.com//marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_ ` + `통화명`
- 각 통화별 일일 환율 정보 url - `https://finance.naver.com//marketindex/exchangeDailyQuote.nhn?marketindexCd=FX`  + `통화명`



# 2. 스크래핑



> ### 1) 통화명 스크래핑 

 우선 각 통화별 url 에 통화명이 들어가므로 통화명을 스크래핑 해서 리스트로 저장해보자, 각 통화별 환율 정보 링크가 담킨 href 에서 필요한 부분만 가져왔다.

```python
link = "https://finance.naver.com/marketindex/exchangeList.nhn"
html = urlopen(link)
bsObject = BeautifulSoup(html, "lxml")
bs = bsObject.select("td.tit>a")

country_index = []

for bs2 in bs:
    country_index.append(bs2.get("href")[-6:])
    
print(country_index)
```

![Screenshot_16](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_16.png)

​	:	`country_index` 에 총 44개의 통화이름을 넣어놓았다.

다음으로는 `country_index` 를 이용해서 각 통화별 일일시세 url 를 불러오자 



> ### 2) 각 통화별 일일시세 url 구성

```python
exchange_daily_link = "https://finance.naver.com//marketindex/exchangeDailyQuote.nhn??marketindexCd=FX_"  
link_lst = []
for country_link in country_index:
    link = exchange_daily_link + country_link
    link_lst.append(link)
# 결과 출력
for i in range(len(link_lst)):
    if i > 5: break
    print(link_lst[i])
```

![Screenshot_26](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_26.png)

​	:	`link_lst` 리스트에 각 환율 일일 정보가 담긴 링크를 넣어놓았다.

이제 각 통화에 대한 환율 url 도 알았으니 각 통화에 대한 환율정보를 직접 스크래핑 해보자.

우선 달러에 대해서만 스크래핑을 해보겠다.



> ### 3) USDKRW 스크래핑 - 1

 일일 환율 링크에서는 날짜/매매기준율/전일대비변동율 등 9개의 정보가 테이블의 형태로 들어가 있다. 그 중에 날짜/매매기준율 두 가지 정보만 스크래핑 해보자 

```python

# USD 통화에 대해서 테스트 해보기
sample_link = link_lst[0]

page = 1
html = urlopen(sample_link + "&page=" + str(page))
bs = BeautifulSoup(html, "lxml")

DATE = []
USDKRW = []

# 환율 정보들이 테이블 안에 td 형태로 들어가 있음
bs_select =bs.select("table.tbl_exchange.today tbody tr td")

for i,bs_sub in enumerate(bs_select):
    
  	# 1번째에는 날짜 정보가 , 2번째에는 매매기준율 환율 정보가 들어가 있다
    if i%9== 0:
        date = bs_sub.get_text()
        DATE.append(date)
    if i%9 == 1:
        exchange = float(bs_sub.get_text().replace("," , ""))
        USDKRW.append(exchange)
    
df = pd.DataFrame({"USDKRW" : USDKRW } , index = DATE)
df.head(10)

```

![Screenshot_22](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_22.png)

​	:	USDKRW 에 대해 날짜/매매기준율 스크래핑

이제 전체 페이지에 대해 확장해서 모든 USDKRW 정보를 받아오자  



> ### 4) USDKRW 스크래핑 - 2 

 주식정보와는 다르게 최대 페이지를 넘어가면 페이지 안에 데이터가 없어 비어진 상태로 표시된다.
따라서 `select` 로 찾아서 리턴한 리스트가 비어있을때 `while`루프에 `break` 가 걸리도록 구현하였다.

<img src="C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_24.png" alt="Screenshot_24" style="zoom:80%;" />



`time` 을 import 해서 실행시간도 같이 측정하였다.

```python
import time
start = time.time()

# USD 통화에 대해서 테스트 해보기
sample_link = link_lst[0]
page = 0
DATE = []
USDKRW = []
    
while(1):
    page += 1
    html = urlopen(sample_link + "&page=" + str(page))
    bs = BeautifulSoup(html, "lxml")
    bs_select =bs.select("table.tbl_exchange.today tbody tr td")

    # 마지막 페이지를 넘어가면 break
    if not len(bs_select): break
    
	# html-table에서 9개의 정보가 행으로 담겨져있다, 여기서 날짜/매매기준율 2가지 정보만 가져옴
    for i,bs_sub in enumerate(bs_select):
        if i%9== 0:
            date = bs_sub.get_text()
            DATE.append(date)
        if i%9 == 1:
            exchange = float(bs_sub.get_text().replace("," , ""))
            USDKRW.append(exchange)

print(" 실행 시간 : {} (초) ".format(time.time() - start))

df = pd.DataFrame({"USDKRW" : USDKRW } , index = DATE)
df.head(10)
print("데이터 개수 : " , len(df))

```

![Screenshot_25](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_25.png)

​	:	실행시간이 34초로 생각보다 빨리 끝났다.

이제 데이터가 잘 들어와 있는지 확인해보자

​	![Screenshot_27](C:\Users\Ando\Developer\WebCrawler\study\Naver_Finance_Scrapping\Screenshot_27.png)

​	:	마지막 데이터가 2004년 4월으로 7년치 정도의 환율정보가 `df` 변수에 들어가 있다.

이제 모든 통화에 대해서 스크래핑을 진행하고 xlsx 파일로 저장해보자



> ### 5) 모든 통화에 대해서 스크래핑 



```python


import time
start = time.time()

# 모든 ㄱ
def get_countries_daily_exchange():
    
    for country in 
    pass


while(1):
    page += 1
    html = urlopen(sample_link + "&page=" + str(page))
    bs = BeautifulSoup(html, "lxml")
    bs_select =bs.select("table.tbl_exchange.today tbody tr td")

    # 마지막 페이지를 넘어가면 break
    if not len(bs_select): break
    
	# html-table에서 9개의 정보가 행으로 담겨져있다, 여기서 날짜/매매기준율 2가지 정보만 가져옴
    for i,bs_sub in enumerate(bs_select):
        if i%9== 0:
            date = bs_sub.get_text()
            DATE.append(date)
        if i%9 == 1:
            exchange = float(bs_sub.get_text().replace("," , ""))
            USDKRW.append(exchange)

print(" 실행 시간 : {} (초) ".format(time.time() - start))

df = pd.DataFrame({"USDKRW" : USDKRW } , index = DATE)
df.head(10)
print("데이터 개수 : " , len(df))



```









> 원하는 통화만 골라서 스크래핑





> 기존의 데이터를 기반으로 환율 정보 업데이트







# 3. 전체 코드







# 4. 참고





> 통화명 스크래핑 , 한글은 제외하고 영어

> 한 국가에 대해 스크래핑 해보기



앞서 해본 주식 스크래핑처럼 각 통화에 따른 환율들은 아래 url 로 구성되있음

`https://finance.naver.com//marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_ ` + `통화명`

```python

base_link = "https://finance.naver.com//marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_"  
link_lst = []
for country_link in country_index:
    link = base_link + country_link
    link_lst.append(link)



```

